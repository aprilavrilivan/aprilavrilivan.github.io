<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Fun With Diffusion Models!</title>
  <meta name="description" content="CS180/280A Project 5: Fun With Diffusion Models!" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <style>
    /* ------------------------------
       Theme & Reset
    ------------------------------ */
    :root{
      --bg: #0b0c10;
      --panel: #111318;
      --text: #e6e8ec;
      --muted: #a6adbb;
      --accent: #7c9cff;
      --accent-2: #4ad6a7;
      --bdr: #1e2230;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius-xl: 18px;
      --radius-lg: 14px;
      --radius-md: 12px;
      --radius-sm: 10px;
      --blur: saturate(120%) blur(0px);
    }
    [data-theme="light"]{
      --bg: #f6f7fb;
      --panel: #ffffff;
      --text: #0b1220;
      --muted: #5c6475;
      --accent: #3a66ff;
      --accent-2: #0dbb8e;
      --bdr: #e8ebf3;
      --shadow: 0 16px 40px rgba(16,24,40,.08);
    }
    * { box-sizing: border-box; }
    html, body { height: 100%; }
    body {
      margin: 0;
      font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      background: radial-gradient(1200px 600px at 10% -10%, rgba(124,156,255,.12), transparent 60%),
                  radial-gradient(900px 500px at 100% 0%, rgba(74,214,167,.12), transparent 60%),
                  var(--bg);
      color: var(--text);
      line-height: 1.6;
    }

    /* ------------------------------
       Layout
    ------------------------------ */
    .wrap { max-width: 1400px; margin: 0 auto; padding: 32px 20px 80px; }
    header.site {
      position: sticky; top: 0; z-index: 50;
      backdrop-filter: var(--blur);
      background: color-mix(in oklab, var(--bg) 70%, transparent);
      border-bottom: 1px solid var(--bdr);
    }
    .site-inner { max-width: 1080px; margin: 0 auto; padding: 14px 20px; display: flex; align-items: center; gap: 12px; }
    .logo {
      width: 40px; height: 40px; display: grid; place-items:center; border-radius: 12px;
      background: linear-gradient(135deg, var(--accent), var(--accent-2));
      color: #fff; font-weight: 800;
      box-shadow: var(--shadow);
    }
    .brand { font-weight: 700; letter-spacing: .3px; }
    .grow { flex: 1; }

    .actions { display: flex; align-items: center; gap: 10px; }
    .btn, a.btn { appearance: none; border: 0; cursor: pointer; text-decoration: none; color: #fff; font-weight: 600; }
    .btn.primary { padding: 10px 14px; border-radius: 10px; background: linear-gradient(135deg, var(--accent), var(--accent-2)); box-shadow: var(--shadow); transition: transform .2s ease, box-shadow .2s ease, filter .2s ease; }
    .btn.primary:hover { transform: translateY(-1px); filter: saturate(110%); }
    .btn.ghost { padding: 10px 12px; border-radius: 10px; color: var(--text); background: transparent; border: 1px solid var(--bdr); }

    h1.page-title { font-size: clamp(22px, 2.4vw, 32px); margin: 18px 0 8px; }
    p.lead { color: var(--muted); margin: 0 0 22px; }

    /* ------------------------------
       Panels
    ------------------------------ */
    .panel { background: var(--panel); border: 1px solid var(--bdr); border-radius: var(--radius-xl); box-shadow: var(--shadow); overflow: hidden; }
    .panel .panel-hd { padding: 18px 20px; border-bottom: 1px solid var(--bdr); display: flex; align-items: center; justify-content: space-between; gap: 10px; }
    .panel .panel-hd h2 { margin: 0; font-size: 18px; }
    .panel .panel-bd { padding: 14px 16px 6px; }

    /* ------------------------------
       Tables ‚Üí Responsive Cards
    ------------------------------ */
    .tbl { width: 100%; border-collapse: separate; border-spacing: 0; }
    .tbl th, .tbl td { padding: 12px 14px; border-bottom: 1px solid var(--bdr); vertical-align: middle; }
    .tbl thead th { text-align: left; font-size: 13px; letter-spacing: .4px; color: var(--muted); text-transform: uppercase; }
    .tbl tbody tr { transition: background .2s ease, transform .08s ease; }
    .tbl tbody tr:hover { background: color-mix(in oklab, var(--panel) 85%, #000 15%); }
    .tbl img { width: 180px; height: auto; border-radius: 12px; display: block; border: 1px solid var(--bdr); box-shadow: var(--shadow); }

    /* Make it look like card list on small screens */
    @media (max-width: 760px){
      .tbl thead { display: none; }
      .tbl, .tbl tbody, .tbl tr, .tbl td { display: block; width: 100%; }
      .tbl tr { background: var(--panel); border: 1px solid var(--bdr); border-radius: var(--radius-lg); margin: 10px 0 16px; padding: 12px; }
      .tbl td { border: 0; padding: 8px 0; }
      .tbl td[data-label]::before { content: attr(data-label)"Ôºö"; display: inline-block; min-width: 9em; color: var(--muted); font-weight: 600; }
      .tbl img { width: 100%; }
    }

    /* Image zoom on hover */
    .thumb { position: relative; overflow: hidden; border-radius: 12px; }
    .thumb img { transform: scale(1); transition: transform .35s ease; }
    .thumb:hover img { transform: scale(1.04); }

    /* Tag pills for shifts */
    .pills { display: inline-flex; gap: 8px; flex-wrap: wrap; }
    .pill { display: inline-flex; align-items: center; gap: 6px; font-weight: 600; font-size: 12px; padding: 6px 10px; border-radius: 999px; border: 1px dashed var(--bdr); color: var(--text); background: color-mix(in oklab, var(--panel) 85%, #000 15%); }
    .pill .dot { width: 8px; height: 8px; border-radius: 999px; background: var(--accent); box-shadow: 0 0 0 2px color-mix(in oklab, var(--accent) 20%, transparent); }
    .pill.red .dot { background: #ff6b6b; }
    .pill.green .dot { background: #4ad6a7; }

    /* Footer */
    footer { margin: 28px 0; display: flex; align-items: center; gap: 12px; }
    .link { color: #fff; text-decoration: none; }

    /* Back button */
    .back-btn { display: inline-flex; align-items: center; gap: 8px; font-weight: 700; padding: 12px 16px; border-radius: 12px; border: 1px solid var(--bdr); background: linear-gradient(180deg, color-mix(in oklab, var(--panel) 90%, #fff 10%), var(--panel)); text-decoration: none; color: var(--text); box-shadow: var(--shadow); transition: transform .2s ease, background .2s ease; }
    .back-btn:hover { transform: translateY(-1px); }

    /* Utility */
    .muted { color: var(--muted); }
    .right { text-align: right; }

    /* Mini step box */
    .mini-box {
      margin: 12px 4px 8px;
      background: color-mix(in oklab, var(--panel) 92%, #000 8%);
      border: 1px dashed var(--bdr);
      border-radius: 12px;
      box-shadow: var(--shadow);
      padding: 12px 14px;
    }
    .mini-box .mini-hd{
      display:flex; align-items:center; justify-content:space-between; gap:10px;
      font-weight:700; font-size:14px;
    }
    .mini-box .mini-hd .hint{ color: var(--muted); font-weight:600; font-size:20px; }
    .mini-box .mini-bd{ margin-top:10px; color: var(--text); }
    .mini-box ol{ margin: 6px 0 0 18px; padding:0; }
    .mini-box li{ margin: 4px 0; line-height: 1.5; }
    .mini-toggle{
      appearance:none; border:1px solid var(--bdr); background:transparent; color:var(--text);
      font-weight:600; border-radius:10px; padding:6px 10px; cursor:pointer;
    }
    .mini-toggle:hover{ filter:saturate(110%); transform: translateY(-1px); }
    @media (max-width:760px){ .mini-box{ padding: 10px 12px; } }

    
    .result-box {
      margin: 10px 0;
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
    }
    .result-box .thumb {
      flex: 1 1 200px;
      max-width: 300px;
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid var(--bdr);
      box-shadow: var(--shadow);
    }
    .result-box img {
      width: 100%;
      height: auto;
      display: block;
    }
    /* ÂçïÁã¨ÊîæÂ§ß main part ÈÇ£‰∏ÄÂº† */
    .result-box .large-box {
      flex: 1 1 450px;  /* Ë∞ÉÊï¥Âü∫Á°ÄÂÆΩÂ∫¶ */
      max-width: 650px; /* ËÆæÁΩÆÊúÄÂ§ßÂÆΩÂ∫¶ */
    }

      .result-line {
      display: flex;
      justify-content: space-between; /* Êàñ center */
      gap: 12px;
      flex-wrap: nowrap; /* Âº∫Âà∂‰∏çÊç¢Ë°å */
    }
    .result-line .thumb {
      flex: 1 1 0;
      max-width: 180px; /* ÊéßÂà∂ÂçïÂº†ÂõæÂÆΩÂ∫¶ */
    }
    .result-line img {
      width: 100%;
      height: auto;
      display: block;
    }
    
    .caption {
      text-align: center;
      font-size: 13px;
      color: var(--muted);
      margin-top: 6px;
    }
  </style>
</head>
    
<body>
  <!-- Sticky Header -->
  <header class="site">
    <div class="site-inner">
      <div class="logo" aria-hidden="true">P2</div>
      <div class="brand">CS180/280A ¬∑ Project 5</div>
      <div class="grow"></div>
      <div class="actions">
        <button class="btn ghost" id="themeToggle" aria-label="Switch Theme">üåì Theme</button>
        <a class="btn primary" href="../index.html">back to main</a>
      </div>
    </div>
  </header>

  <main class="wrap">
    <h1 class="page-title">Fun With Diffusion Models!</h1>
    <p class="lead">This project aims to explore Diffusion Models</span>.</p>
    
    <!-- P1 -->
    <section class="panel" aria-labelledby="sec-simple">
      <div class="panel-hd">
        <h2 id="sec-simple">Part 0: Setup</h2>
        <span class="muted">4 sections in total</span>
      </div>
      <div class="panel-bd">
        <!-- Small step box -->
        <div class="mini-box" id="0.1">
          <div class="mini-hd">
            <span>Part 0</span>
            <span class="hint">0.1</span>
            <button class="mini-toggle" type="button" data-target="#0.1-bo">Hide</button>
          </div>
          <div class="mini-bd" id="0.1-body">
            <ol>
              <li><p>This part aims to play with DeepFloyd, which is a two stage diffusion model trained by Stability AI. The first step
                  I did is to create some imaginative prompts, and encode them to vectors using T5 Text Encoder Embeddings Generator. 
                  I created 11 prompts, as shown below in the generator's website:</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/questions.png" alt="Box filter result 1">
                      <div class="caption">the prompts</div>
                    </div>
                  </div>
                </li>
              <li>
                <p>Then I fed the embedded vectors to DeepFloyd, with random seed = 100. The following are three sets of results</p>
                <p>--------------------------------------------------------------------------------------------------------------------------</p>
                <p>Prompt: "a wide angle photo of the campanile reflected in a rain puddle at night"</p>
                <p>Reflect: The three pictures are all clear, and they all matches the key words in prompt: wide angle/campanile/reflect/rain puddle/night. As the inference 
                  steps grow, the pictures gradually contain more details (because the model can diffuse more noise), and the angles of camera becomes wider.</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/prompt1_20.png" alt="Box filter result 1">
                      <div class="caption">20 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt1_40.png" alt="Box filter result 1">
                      <div class="caption">40 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt1_80.png" alt="Box filter result 1">
                      <div class="caption">80 num_inference_steps</div>
                    </div>
                  </div>
                <p>Prompt: "a watercolor painting of robots studying under paper lanterns in a quiet library"</p>
                <p>Reflect: All three pictures didn't manage to obey all the instructions in the prompt: Only the third picture captures the detail 
                  "paper lanters", and only the second image captures the detail "library", but it doesn't show the keyword "studying". The robots tend to have 
                  wrong number of legs, and their hands can't be characterized well.
                  But anyway, at least all three pictures follow the instruction of "watercolor painting" and "robotics", and overall, the images are clear, with more details added
                  as the inference steps grow, which aligns the observation in the first set of images.</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/prompt2_20.png" alt="Box filter result 1">
                      <div class="caption">20 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt2_40.png" alt="Box filter result 1">
                      <div class="caption">40 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt2_80.png" alt="Box filter result 1">
                      <div class="caption">80 num_inference_steps</div>
                    </div>
                  </div>
                <p>Prompt: "an aerial photograph of terraced rice fields shaped like a spiral galaxy"</p>
                <p>Reflect: The terraced rice fields are more and more shaped like a spiral galaxy as the inference steps grow, indicating that the model could better understand the semantic in the prompt as the inference time becomes longer. Overall, the three
                    images all obeys the instructions in the prompt, and are all clear without distinct noise„ÄÇ</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/prompt3_20.png" alt="Box filter result 1">
                      <div class="caption">20 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt3_40.png" alt="Box filter result 1">
                      <div class="caption">40 num_inference_steps</div>
                    </div>
                    <div class="thumb">
                      <img src="media/prompt3_80.png" alt="Box filter result 1">
                      <div class="caption">80 num_inference_steps</div>
                    </div>
                  </div>
              </li>
            </ol>
          </div>
        </div>
    </section>
    <!---------------- P2 ----------->
    <section class="panel" aria-labelledby="sec-simple">
      <div class="panel-hd">
        <h2 id="sec-simple">Part 1: Sampling Loops</h2>
        <span class="muted">9 section in total</span>
      </div>
      <div class="panel-bd">
        <!-- Small step box -->
        <div class="mini-box" id="1.1">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.1</span>
            <button class="mini-toggle" type="button" data-target="#1.1-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.1-body">
            <ol>
              <li><p>The following demonstrates a simple fwd proc of diffusion sampling</p>
                  <p>Here is the critical part of the forward(im, t) function: choose an alpha, sqrt the alpha
                    , generate a pure noise img, and merge the noise img and the orignal img in a weighted way according to alpha.</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/forward_proc.png" alt="Box filter result 1">
                      <div class="caption">the forward process</div>
                    </div>
                  </div>
              </li>
              <li>
                <p>
                  Here are the Campanile at noise level [250, 500, 750]:
                </p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/0.png" alt="Box filter result 1">
                      <div class="caption">Berkeley Campanile</div>
                    </div>
                </div>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/250.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=250</div>
                    </div>
                    <div class="thumb">
                      <img src="media/500.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=500</div>
                    </div>
                    <div class="thumb">
                      <img src="media/750.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=750</div>
                    </div>
                  </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.2">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.2</span>
            <button class="mini-toggle" type="button" data-target="#1.2-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.2-body">
            <ol>
              <li><p>Using classical method (i.e. Gaussian Blurring) to denoise the above images is hard. I tried my best to denoise them
                    by increasing the Gaussian kernal size w.r.t larger noise step, but it's still hard to identify the campanile when 
                    noise step gets larger.</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/blur250.png" alt="Box filter result 1">
                      <div class="caption">Gaussian Blur Denoising at t=250</div>
                    </div>
                    <div class="thumb">
                      <img src="media/blur500.png" alt="Box filter result 1">
                      <div class="caption">Gaussian Blur Denoising at t=500</div>
                    </div>
                    <div class="thumb">
                      <img src="media/blur750.png" alt="Box filter result 1">
                      <div class="caption">Gaussian Blur Denoising at t=250</div>
                    </div>
                  </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.3">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.3</span>
            <button class="mini-toggle" type="button" data-target="#1.3-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.3-body">
            <ol>
              <li><p>It would be a better choice to use One-Step Denoising by the stage_1.unet of the DeepFloyd model. The model takes in the 
                    [noise image, prompt "a high quality photo", noise step t], and outputs the estimated one-step noise e. We can use the reverse
                     formula to get clean x_0:</p>
                  <div class="result-box">
                    <div class="thumb">
                      <img src="media/reverseFormula.png" alt="Box filter result 1">
                    </div>
                  </div>
                <p>Here are the results:</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/deno250.png" alt="Box filter result 1">
                      <div class="caption">One-Step Denoised Campanile at t=250</div>
                    </div>
                    <div class="thumb">
                      <img src="media/deno500.png" alt="Box filter result 1">
                      <div class="caption">One-Step Denoised Campanile at t=500</div>
                    </div>
                    <div class="thumb">
                      <img src="media/deno750.png" alt="Box filter result 1">
                      <div class="caption">One-Step Denoised Campanile at t=750</div>
                    </div>
                  </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.4">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.4</span>
            <button class="mini-toggle" type="button" data-target="#1.4-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.4-body">
            <ol>
              <li><p>To achieve even better denoising outcome, we can use iterative denoising. We can iteratively denoise from t=990 to t=0, 
                      with a stride=30. To do this, first I implemented a strided_timesteps list, which contains timesteps like 990,960,930...,60,30,0, and 
                      also initialize the timesteps to stage_1 model using the function stage_1.scheduler.set_timesteps(timesteps=strided_timesteps):</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/createStride.png" alt="Box filter result 1">
                    </div>
                  </div>
                </li>
              <li>
                <p>Then I implemented the iterative_denoise function, which translates the following iterative denoise formula:</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/iterativeFormula.png" alt="Box filter result 1">
                    </div>
                </div>
                <p>to code:</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/getAlpha.png" alt="Box filter result 1">
                    </div>
                    <div class="thumb large-box">
                      <img src="media/compFormula.png" alt="Box filter result 1">
                    </div>
                  </div>
              </li>
              <li>
                <p>After that, I tried to add noise to the Campanilie picture to timestep[10], which is equivalent to t=690, and denoise back
                with stride=30 till t=0. I saved the progress every 5 timestep (i.e. every t=150 steps). I compared the final result
                  with one-step denoising and Gaussian Blurring, finding the iterative denoise versions achieves the best result.</p>
                <div class="result-box">
                    <div class="thumb">
                      <img src="media/90.png" alt="Box filter result 1">
                      <div class="caption"> Noisy Campanile at t=90</div>
                    </div>
                    <div class="thumb">
                      <img src="media/240.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=240</div>
                    </div>
                    <div class="thumb">
                      <img src="media/390.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=390</div>
                    </div>
                    <div class="thumb">
                      <img src="media/540.png" alt="Box filter result 1">
                      <div class="caption"> Noisy Campanile at t=540</div>
                    </div>
                    <div class="thumb">
                      <img src="media/690.png" alt="Box filter result 1">
                      <div class="caption">Noisy Campanile at t=690</div>
                    </div>
                  </div>
                  <div class="result-box">
                    <div class="thumb">
                      <img src="media/original.png" alt="Box filter result 1">
                      <div class="caption"> original Campanilie </div>
                    </div>
                    <div class="thumb">
                      <img src="media/iterative_deno.png" alt="Box filter result 1">
                      <div class="caption">Iteratively Denoised Campanile</div>
                    </div>
                    <div class="thumb">
                      <img src="media/onestep_deno.png" alt="Box filter result 1">
                      <div class="caption">One-Step Denoised Campanile</div>
                    </div>
                    <div class="thumb">
                      <img src="media/gaus_deno.png" alt="Box filter result 1">
                      <div class="caption">Gaussian Blurred Campanile</div>
                    </div>
                  </div>
              </li>
            </ol>
          </div>
        </div>
      <!-- Small step box -->
        <div class="mini-box" id="1.5">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.5</span>
            <button class="mini-toggle" type="button" data-target="#1.5-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.5-body">
            <ol>
              <li><p>To generate arbitarily denoised images, we could add noise to the Campanile image to time t=1000 (let i_start = 0), which tranforms it into a pure noise image. Then we perform the same 
              iteratively denoise process till time =0, and see what kind of clean images the model would output:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/sample1.png" alt="Box filter result 1">
                    <div class="caption">sample1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/sample2.png" alt="Box filter result 1">
                    <div class="caption">sample2</div>
                  </div>
                  <div class="thumb">
                    <img src="media/sample3.png" alt="Box filter result 1">
                    <div class="caption">sample3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/sample4.png" alt="Box filter result 1">
                    <div class="caption">sample4</div>
                  </div>
                  <div class="thumb">
                    <img src="media/sample5.png" alt="Box filter result 1">
                    <div class="caption">sample5</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.6">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.6</span>
            <button class="mini-toggle" type="button" data-target="#1.6-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.6-body">
            <ol>
              <li><p>To make the above randomly sampled images perform higher quality, we can adopt the CFG trick: which is that at each denoising stage, 
              we run the model twice, one with prompt "a high quality photo", another with null prompt. Then we do weighted average to the output noise and 
              run a strided denoising step. Here are the critical code snippets in the function iterative_denoise_cfg:</p>
              <div class="result-box">
                <div class="thumb large-box">
                    <img src="media/CFGCode.png" alt="Box filter result 1">
                    <div class="caption">code snippets of weighted averaging noise</div>
                  </div>
              </div>
              <p>Here are five sampled diffution output images using CFG. The quality is much higher than that in the previous srection.</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/CFG1.png" alt="Box filter result 1">
                    <div class="caption">sample1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/CFG2.png" alt="Box filter result 1">
                    <div class="caption">sample2</div>
                  </div>
                  <div class="thumb">
                    <img src="media/CFG3.png" alt="Box filter result 1">
                    <div class="caption">sample3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/CFG4.png" alt="Box filter result 1">
                    <div class="caption">sample4</div>
                  </div>
                  <div class="thumb">
                    <img src="media/CFG5.png" alt="Box filter result 1">
                    <div class="caption">sample5</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.7.0">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.7.0</span>
            <button class="mini-toggle" type="button" data-target="#1.7.0-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.7.0-body">
            <ol>
              <li><p>We know that the model tends to be more "hallucinative" when we add more noise to the original picture and use the model to 
              denoise it back. The following are edits of the Campanile image, using the given prompt at noise levels [1, 3, 5, 7, 10, 20] with the conditional text prompt "a high quality photo":</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/campanile1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/campanile3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/campanile5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/campanile7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/campanile10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/campanile20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/original.png" alt="Box filter result 1">
                    <div class="caption">original companile</div>
                  </div>
                </div>
              </li>
              <li><p>I also tested this on two of my own pictures:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/mypic1_1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic1_3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic1_5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic1_7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic1_10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/mypic1_20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic1_original.png" alt="Box filter result 1">
                    <div class="caption">original companile</div>
                  </div>
                </div>
                <div class="result-box">
                  <div class="thumb">
                    <img src="media/mypic2_1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic2_3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic2_5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic2_7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic2_10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/mypic2_20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mypic2_original.png" alt="Box filter result 1">
                    <div class="caption">original companile</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
      <!-- Small step box -->
        <div class="mini-box" id="1.7.1">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.7.1</span>
            <button class="mini-toggle" type="button" data-target="#1.7.1-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.7.1-body">
            <ol>
              <li><p>When we start with some nonrealistic images (e.g. painting, a sketch, some scribbles), the above pipeline
                tends to project it onto the natural image manifold. For example, the following pixel-style face from the web:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/face1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/face3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/face5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/face7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/face10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/face20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/faceOriginal.png" alt="Box filter result 1">
                    <div class="caption">original web pic</div>
                  </div>
                </div>
              </li>
              <li><p>I also tested this on two pictures drawn by myself:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/stickman1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/stickman3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/stickman5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/stickman7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/stickman10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/stickman20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/stickmanOriginal.png" alt="Box filter result 1">
                    <div class="caption">original stickman</div>
                  </div>
                </div>
                <div class="result-box">
                  <div class="thumb">
                    <img src="media/gem1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/gem3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/gem5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/gem7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/gem10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/gem20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/gemOriginal.png" alt="Box filter result 1">
                    <div class="caption">original germ</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
      <!-- Small step box -->
        <div class="mini-box" id="1.7.2">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.7.2</span>
            <button class="mini-toggle" type="button" data-target="#1.7.2-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.7.2-body">
            <ol>
              <li><p>We can also use this process to do inpainting. That is, given a mask, the diffusion process only edits the area where the mask is 1. To realize this, at every diffusing step
              when we get the result x_t, we only keep the unmasked area, and replace the masked area with the original corresponding image at that stage. The following is the critical 
              part of the inpainting function:</p>
              <div class="result-box">
                  <div class="thumb large-box">
                    <img src="media/codeInpainting.png" alt="Box filter result 1">
                  </div>
              </div>
              </li>
              <li>
              <p>Here I first inpainted the Companile using my own mask:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/original.png" alt="Box filter result 1">
                    <div class="caption">Orginal Companile</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mask1.png" alt="Box filter result 1">
                    <div class="caption">The mask</div>
                  </div>
                  <div class="thumb">
                    <img src="media/holeToFill.png" alt="Box filter result 1">
                    <div class="caption">Area to replace</div>
                  </div>
                  <div class="thumb">
                    <img src="media/inpaintedCampanile.png" alt="Box filter result 1">
                    <div class="caption">The inpainted picture</div>
                  </div>
                </div>
              </li>
              <li><p>I also tested this on two pictures drawn by myself:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/airplaneOriginal.png" alt="Box filter result 1">
                    <div class="caption">Orginal Airplane</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mask2.png" alt="Box filter result 1">
                    <div class="caption">The mask</div>
                  </div>
                  <div class="thumb">
                    <img src="media/toreplace2.png" alt="Box filter result 1">
                    <div class="caption">Area to replace</div>
                  </div>
                  <div class="thumb">
                    <img src="media/airplainInpainted.png" alt="Box filter result 1">
                    <div class="caption">The inpainted picture</div>
                  </div>
              </div>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/railwayOriginal.png" alt="Box filter result 1">
                    <div class="caption">Orginal Companile</div>
                  </div>
                  <div class="thumb">
                    <img src="media/mask3.png" alt="Box filter result 1">
                    <div class="caption">The mask</div>
                  </div>
                  <div class="thumb">
                    <img src="media/toreplace3.png" alt="Box filter result 1">
                    <div class="caption">Area to replace</div>
                  </div>
                  <div class="thumb">
                    <img src="media/railwayInpainted.png" alt="Box filter result 1">
                    <div class="caption">The inpainted picture</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.7.3">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.7.3</span>
            <button class="mini-toggle" type="button" data-target="#1.7.3-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.7.3-body">
            <ol>
              <li><p>Now, we will do the same thing as the previous section, but guide the projection with a text prompt.</p>
              <p>Here is the version of berkeley Campanile with the prompt:"a wide angle photo of the campanile reflected in a rain puddle at night":</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/prompt1_1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt1_3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt1_5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt1_7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt1_10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/prompt1_21.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/original.png" alt="Box filter result 1">
                    <div class="caption">original campanile</div>
                  </div>
                </div>
              </li>
              <li><p>I also tested this on two pictures drawn by myself:</p>
                <p>Prompt: "a watercolor painting of robots studying under paper lanterns in a quiet library"</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/prompt2_1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt2_3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt2_5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt2_7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt2_10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/prompt2_21.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/prompt2Original.png" alt="Box filter result 1">
                    <div class="caption">original robot</div>
                  </div>
                </div>
                <p>Prompt: "an aerial photograph of terraced rice fields shaped like a spiral galaxy"</p>
                <div class="result-box">
                  <div class="thumb">
                    <img src="media/galaxy1.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/galaxy3.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=3</div>
                  </div>
                  <div class="thumb">
                    <img src="media/galaxy5.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=5</div>
                  </div>
                  <div class="thumb">
                    <img src="media/galaxy7.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=7</div>
                  </div>
                  <div class="thumb">
                    <img src="media/galaxy10.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=10</div>
                  </div>                  
                  <div class="thumb">
                    <img src="media/galaxy20.png" alt="Box filter result 1">
                    <div class="caption">SDEdit with i_start=20</div>
                  </div>
                  <div class="thumb">
                    <img src="media/galaxyOriginal.png" alt="Box filter result 1">
                    <div class="caption">original galaxy</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.8">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.8</span>
            <button class="mini-toggle" type="button" data-target="#1.8-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.8-body">
            <ol>
              <li><p>Then, I implemented a visual anagram using diffusion. The picture describes different scenes when fliped upsidedown. To do this, I did two CFGs in one timestep, one for upright picture and one for upside uown picture,
                and then average them together</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/anacode1.png" alt="Box filter result 1">
                    <div class="caption">CFG for upright</div>
                  </div>
                  <div class="thumb">
                    <img src="media/anacode2.png" alt="Box filter result 1">
                    <div class="caption">CFG for upsidedown</div>
                  </div>
              </div>
              <div class="result-box">
                  <div class="thumb large-box">
                    <img src="media/anacode3.png" alt="Box filter result 1">
                    <div class="caption">merge the noise together</div>
                  </div>
                </div>
              </li>
              <li>
                <p>p1 = "A cat"</p>
                <p>p2 = "A dragon"</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/anagram_1.png" alt="Box filter result 1">
                    <div class="caption">upright</div>
                  </div>
                  <div class="thumb">
                    <img src="media/anagram_2.png" alt="Box filter result 1">
                    <div class="caption">upsidedown</div>
                  </div>
                </div>
              </li>
              <li>
                <p>p1 = "A hooded person sitting on a rooftop"</P>
                <p>p2 = "A fox face with bright eyes" </p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/anagram_3.png" alt="Box filter result 1">
                    <div class="caption">upright</div>
                  </div>
                  <div class="thumb">
                    <img src="media/anagram_4.png" alt="Box filter result 1">
                    <div class="caption">upsidedown</div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="1.9">
          <div class="mini-hd">
            <span>Part 1</span>
            <span class="hint">1.9</span>
            <button class="mini-toggle" type="button" data-target="#1.9-bo">Hide</button>
          </div>
          <div class="mini-bd" id="1.9-body">
            <ol>
              <li><p>We can also create hybrid pictures using the same diffusion pipeline. The hybrid picture performs different meanings when 
              looked from close to far. To realize this, I did two CFGs in a single timestep with different guiding prompts. Then, I merge the 
              low frequency part of the noise from the first CFG with the high frequency part of the noise from the second CFG, and performs a 
              denoising step. The critical code snippets are shown below:</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/hybrid1.png" alt="Box filter result 1">
                    <div class="caption">CFG for prompt 1</div>
                  </div>
                  <div class="thumb">
                    <img src="media/hybrid2.png" alt="Box filter result 1">
                    <div class="caption">CFG for prompt 2</div>
                  </div>
              </div>
              <div class="result-box">
                  <div class="thumb large-box">
                    <img src="media/merge_noise.png" alt="Box filter result 1">
                    <div class="caption">merge the noise(with diff freq) together</div>
                  </div>
                </div>
              </li>
              <li>
                <p>p1(low freq) = "A mushroom"</p>
                <p>p2(high freq) = "A flower"</p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/hybrid_1.png" alt="Box filter result 1">
                  </div>
                </div>
              </li>
              <li>
                <p>p1(low freq) = "A mountain"</P>
                <p>p2(high freq) = "A Christmas tree" </p>
              <div class="result-box">
                  <div class="thumb">
                    <img src="media/hybrid_2.png" alt="Box filter result 1">
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
    </section>   
          
    <!---------------- P3 ----------->
    <section class="panel" aria-labelledby="sec-simple">
      <div class="panel-hd">
        <h2 id="sec-simple">Part 2:Flow Matching from Scratch!</h2>
        <span class="muted">1 section in total</span>
      </div>
      <div class="panel-bd">
        <!-- Small step box -->
        <div class="mini-box" id="2.1.1ÔΩû2.1.2">
          <div class="mini-hd">
            <span>Part 2.1.1ÔΩû2.1.2</span>
            <span class="hint">2.1.1ÔΩû2.1.2</span>
            <button class="mini-toggle" type="button" data-target="#2.1.1ÔΩû2.1.2-bo">Hide</button>
          </div>
          <div class="mini-bd" id="2.1.1ÔΩû2.1.2-body">
            <ol>
              <li><p>In this section, I first constructed a standard UNet following the official instruction. The ultimate goal in this section
                is to train a UNet that translate a noisy image back to its clean version. To do this, I first create a set of noisy images by 
                adding Gaussian noise to clean images, visualized as below:
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/noise_number.png" alt="Box filter result 1">
                      <div class="caption">clean pics adding noise with sigma=[0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]</div>
                    </div>
                  </div>
              </li>
              <li><p>Then  I set up a training pipeline to train the UNet, with the following parameters:</p> 
                <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/train_para.png" alt="Box filter result 1">
                      <div class="caption">Sample along rays function</div>
                    </div>
                  </div>
                <p>Here is the mse_loss during training:</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/loss_curve.png" alt="Box filter result 1">
                      <div class="caption">The loss curve</div>
                    </div>
                  </div>
                <p>And here is the comparism of the original clean images, the images adding noise with sigma=0.5, the prediction from the first epoch and the 
                prediction from the 5th epoch of training;</p>
                <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/prediction.png" alt="Box filter result 1">
                    </div>
                  </div>
              </li>
              <li>
                <p>Then, I did the OOD test, which used the well trained UNet to predict noisy pictures with sigma values: sigma=[0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0] :</p>
                <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/OOD.png" alt="Box filter result 1">
                    </div>
                  </div>
              </li>
              <li>
                <p>The last experiment is to train the UNet to denoise pure noise. I used the same model training hyperparameters as in 2.1.2.1, but
                with input pictures of pure noise. The following is the loss curve during training:</p>
                <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/losscurvenoise.png" alt="Box filter result 1">
                    </div>
                  </div>
                <p>Here is the prediction on random pure noise by model trained after 1 epoch and 5 epochs:</p>
                <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/average1.png" alt="Box filter result 1">
                    </div>
                  </div>
                <p>We can see that no matter what random noise we feed in, the model tends to output something that looks like a blurry ‚Äú9‚Äù. 
                  This is basically the model collapsing to an ‚Äúaverage digit‚Äù over the training set. The reason is that with an MSE loss, 
                  the best prediction for a given input is the conditional mean E[xÔΩúz]. But here z is pure Gaussian noise and it has almost 
                  no relationship with the target clean image x, so E[xÔΩúz] is roughly just E[x], i.e., the dataset mean
                  (similar to a centroid in clustering). Since the input doesn‚Äôt provide any useful hint about which digit it 
                  should reconstruct, predicting this average-looking digit is an easy way to reduce the overall squared error.
                </p>
              </li>
            </ol>
          </div>
        </div>
        <!-- Small step box -->
        <div class="mini-box" id="2.2.1ÔΩû2.2.6">
          <div class="mini-hd">
            <span>Part 2.2.1ÔΩû2.2.6</span>
            <span class="hint">2.2.1ÔΩû2.2.6</span>
            <button class="mini-toggle" type="button" data-target="#2.2.1ÔΩû2.2.6-bo">Hide</button>
          </div>
          <div class="mini-bd" id="2.2.1ÔΩû2.2.6-body">
            <ol>
              <li><p>This section explores the flow matching model. To let the original UNet support fm function, I added the time 
              conditioning block to it, as demonstrated in the official diagram. Then I managed to set up a training pipeline following the 
              pseudocode provided in the hw website, the following is the resulting loss function during 20 epochs of training:</p>
                  <div class="result-box">
                    <div class="thumb large-box">
                      <img src="media/fmloss.png" alt="Box filter result 1">
                      <div class="caption">the loss function of fm training</div>
                    </div>
                  </div>
              </li>
              <li><p>I managed to visualize the fm model prediction after 1, 5, 10, and 20 epochs:</p> 
                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/fm1.png" alt="Box filter result 1">
                    </div>
                </div>
                                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/fm5.png" alt="Box filter result 1">
                    </div>
                </div>
                                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/fm10.png" alt="Box filter result 1">
                    </div>
                </div>
                                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/fm20.png" alt="Box filter result 1">
                    </div>
                </div>
              </li>
              <li>
                <p>Finally, I implementes a class-conditioned FM denoiser, which instructs which specific number should the UNet denoise back to.
                To do this, I add two more FCBlocks in  addition to the original blocks, whose job is to guide the denoiser. During training, 
                I randomly let 10% of the one-hot clasifier to be zero, in order to maintain the model's basic denoising capability. During sampling
                I used a CFG style sampling method like that in the diffusion part. Here is the loss funtion after 10 training epochs:</p>
                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/conditionedFMloss.png" alt="Box filter result 1">
                    </div>
                </div>
                <p>I demonstrated the output of model after 1, 5, and 10 training epochs:</p>
                <div class="result-box">
                  <div class="thumb large-box">
                      <img src="media/fmcond1.png" alt="Box filter result 1">
                    </div>
                  <div class="thumb large-box">
                      <img src="media/fmcond5.png" alt="Box filter result 1">
                    </div>
                  <div class="thumb large-box">
                      <img src="media/fmcond10.png" alt="Box filter result 1">
                    </div>
                </div>
              </li>
            </ol>
          </div>
        </div>
    </section> 
  </main>
        
  <script>
    // Theme toggle with localStorage
    const root = document.documentElement;
    const key = 'pg-theme';
    const btn = document.getElementById('themeToggle');
    const saved = localStorage.getItem(key);
    if(saved){ document.documentElement.setAttribute('data-theme', saved); }
    btn.addEventListener('click', () => {
      const current = document.documentElement.getAttribute('data-theme');
      const next = current === 'light' ? 'dark' : 'light';
      document.documentElement.setAttribute('data-theme', next);
      localStorage.setItem(key, next);
    });
    // Tiny toggle for mini-box
    document.querySelectorAll('.mini-toggle').forEach(btn=>{
      btn.addEventListener('click', ()=>{
        const sel = btn.getAttribute('data-target');
        const box = document.querySelector(sel);
        const hidden = box.style.display === 'none';
        box.style.display = hidden ? '' : 'none';
        btn.textContent = hidden ? 'Hide' : 'Show';
      });
    });
  </script>
        
</body>
